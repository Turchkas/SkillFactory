{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2220122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2cc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('images.npy')\n",
    "labels = np.load('labels.npy')\n",
    "test_images = np.load('images_sub.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85336b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "labels = to_categorical(labels, num_classes=26)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df47075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 46, 46, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 23, 23, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 2, 2, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 1, 1, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 26)                13338     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 533,338\n",
      "Trainable params: 533,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f6ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1987 - accuracy: 0.0615 - val_loss: 2.8828 - val_accuracy: 0.1452 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 2.2061 - accuracy: 0.3314 - val_loss: 1.4642 - val_accuracy: 0.5483 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.2658 - accuracy: 0.6039 - val_loss: 1.0058 - val_accuracy: 0.7040 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.9052 - accuracy: 0.7171 - val_loss: 0.8191 - val_accuracy: 0.7487 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.7062 - accuracy: 0.7743 - val_loss: 0.7670 - val_accuracy: 0.7642 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5758 - accuracy: 0.8169 - val_loss: 0.6809 - val_accuracy: 0.7952 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.8441 - val_loss: 0.6662 - val_accuracy: 0.7920 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8668 - val_loss: 0.6290 - val_accuracy: 0.8062 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3325 - accuracy: 0.8898 - val_loss: 0.5922 - val_accuracy: 0.8245 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2848 - accuracy: 0.9065 - val_loss: 0.6261 - val_accuracy: 0.8215 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2324 - accuracy: 0.9232 - val_loss: 0.6705 - val_accuracy: 0.8167 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.2060 - accuracy: 0.9315 - val_loss: 0.7542 - val_accuracy: 0.8138 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.1004 - accuracy: 0.9686 - val_loss: 0.6588 - val_accuracy: 0.8395 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0705 - accuracy: 0.9784 - val_loss: 0.6729 - val_accuracy: 0.8428 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': range(len(predicted_classes)), 'Category': predicted_classes}).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b28a2d4b",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df3dd6",
   "metadata": {},
   "source": [
    "**Попробуем улучшить результат. Добавим padding, чтобы сохранить размерность, BatchNormalization и Dropout после каждого блока для борьбы с переобучением**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f58d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 48, 48, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 48, 48, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 48, 48, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 12, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 12, 12, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               1179904   \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 26)                6682      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,328,314\n",
      "Trainable params: 1,327,162\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(48, 48, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(26, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d21dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3139422",
   "metadata": {},
   "source": [
    "**Сделаем обучение с аугментацией данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e748c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 11s 39ms/step - loss: 3.8744 - accuracy: 0.0501 - val_loss: 3.5232 - val_accuracy: 0.0235 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 3.2135 - accuracy: 0.1159 - val_loss: 2.6720 - val_accuracy: 0.2290 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 2.2717 - accuracy: 0.3425 - val_loss: 1.5988 - val_accuracy: 0.5767 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 1.7006 - accuracy: 0.4921 - val_loss: 1.0638 - val_accuracy: 0.7035 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 1.3562 - accuracy: 0.5908 - val_loss: 0.8826 - val_accuracy: 0.7498 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 1.1571 - accuracy: 0.6443 - val_loss: 0.7206 - val_accuracy: 0.7772 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 1.0187 - accuracy: 0.6908 - val_loss: 0.6169 - val_accuracy: 0.8110 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.9190 - accuracy: 0.7163 - val_loss: 0.5060 - val_accuracy: 0.8510 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.8651 - accuracy: 0.7332 - val_loss: 0.4948 - val_accuracy: 0.8485 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.7834 - accuracy: 0.7545 - val_loss: 0.4297 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.7230 - accuracy: 0.7776 - val_loss: 0.4219 - val_accuracy: 0.8758 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.6741 - accuracy: 0.7878 - val_loss: 0.3916 - val_accuracy: 0.8805 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.6296 - accuracy: 0.8048 - val_loss: 0.3424 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.6005 - accuracy: 0.8084 - val_loss: 0.4719 - val_accuracy: 0.8553 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.5737 - accuracy: 0.8214 - val_loss: 0.2911 - val_accuracy: 0.9105 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.5586 - accuracy: 0.8245 - val_loss: 0.3026 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.5180 - accuracy: 0.8337 - val_loss: 0.2715 - val_accuracy: 0.9190 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.5195 - accuracy: 0.8364 - val_loss: 0.2692 - val_accuracy: 0.9153 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.4888 - accuracy: 0.8439 - val_loss: 0.2652 - val_accuracy: 0.9183 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.4634 - accuracy: 0.8503 - val_loss: 0.2517 - val_accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.4586 - accuracy: 0.8559 - val_loss: 0.2565 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.4496 - accuracy: 0.8577 - val_loss: 0.2345 - val_accuracy: 0.9270 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.4330 - accuracy: 0.8630 - val_loss: 0.2337 - val_accuracy: 0.9265 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.4062 - accuracy: 0.8665 - val_loss: 0.2241 - val_accuracy: 0.9287 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.4132 - accuracy: 0.8663 - val_loss: 0.2075 - val_accuracy: 0.9335 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.3957 - accuracy: 0.8767 - val_loss: 0.1990 - val_accuracy: 0.9395 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.3727 - accuracy: 0.8823 - val_loss: 0.2325 - val_accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.3774 - accuracy: 0.8804 - val_loss: 0.2139 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.3604 - accuracy: 0.8852 - val_loss: 0.1872 - val_accuracy: 0.9408 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.3552 - accuracy: 0.8859 - val_loss: 0.1798 - val_accuracy: 0.9448 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.3466 - accuracy: 0.8866 - val_loss: 0.1978 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.3395 - accuracy: 0.8905 - val_loss: 0.2741 - val_accuracy: 0.9160 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.3205 - accuracy: 0.8972 - val_loss: 0.1895 - val_accuracy: 0.9400 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2999 - accuracy: 0.9049 - val_loss: 0.1555 - val_accuracy: 0.9520 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2810 - accuracy: 0.9111 - val_loss: 0.1452 - val_accuracy: 0.9515 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2813 - accuracy: 0.9092 - val_loss: 0.1478 - val_accuracy: 0.9532 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2650 - accuracy: 0.9168 - val_loss: 0.1554 - val_accuracy: 0.9515 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2701 - accuracy: 0.9124 - val_loss: 0.1417 - val_accuracy: 0.9555 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2560 - accuracy: 0.9159 - val_loss: 0.1490 - val_accuracy: 0.9545 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2495 - accuracy: 0.9197 - val_loss: 0.1533 - val_accuracy: 0.9557 - lr: 5.0000e-04\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2472 - accuracy: 0.9199 - val_loss: 0.1565 - val_accuracy: 0.9520 - lr: 5.0000e-04\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2337 - accuracy: 0.9240 - val_loss: 0.1415 - val_accuracy: 0.9588 - lr: 2.5000e-04\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2283 - accuracy: 0.9243 - val_loss: 0.1365 - val_accuracy: 0.9563 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2242 - accuracy: 0.9265 - val_loss: 0.1446 - val_accuracy: 0.9548 - lr: 2.5000e-04\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2114 - accuracy: 0.9322 - val_loss: 0.1353 - val_accuracy: 0.9600 - lr: 2.5000e-04\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2140 - accuracy: 0.9302 - val_loss: 0.1333 - val_accuracy: 0.9630 - lr: 2.5000e-04\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2085 - accuracy: 0.9304 - val_loss: 0.1380 - val_accuracy: 0.9607 - lr: 2.5000e-04\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2096 - accuracy: 0.9323 - val_loss: 0.1333 - val_accuracy: 0.9597 - lr: 2.5000e-04\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2006 - accuracy: 0.9351 - val_loss: 0.1316 - val_accuracy: 0.9592 - lr: 2.5000e-04\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2095 - accuracy: 0.9334 - val_loss: 0.1413 - val_accuracy: 0.9582 - lr: 2.5000e-04\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1951 - accuracy: 0.9373 - val_loss: 0.1391 - val_accuracy: 0.9595 - lr: 2.5000e-04\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1930 - accuracy: 0.9365 - val_loss: 0.1379 - val_accuracy: 0.9585 - lr: 2.5000e-04\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1943 - accuracy: 0.9367 - val_loss: 0.1343 - val_accuracy: 0.9592 - lr: 1.2500e-04\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1839 - accuracy: 0.9392 - val_loss: 0.1279 - val_accuracy: 0.9620 - lr: 1.2500e-04\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1878 - accuracy: 0.9389 - val_loss: 0.1306 - val_accuracy: 0.9597 - lr: 1.2500e-04\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1772 - accuracy: 0.9433 - val_loss: 0.1302 - val_accuracy: 0.9628 - lr: 1.2500e-04\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1848 - accuracy: 0.9408 - val_loss: 0.1376 - val_accuracy: 0.9600 - lr: 1.2500e-04\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1799 - accuracy: 0.9427 - val_loss: 0.1261 - val_accuracy: 0.9645 - lr: 6.2500e-05\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1869 - accuracy: 0.9394 - val_loss: 0.1264 - val_accuracy: 0.9628 - lr: 6.2500e-05\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1742 - accuracy: 0.9456 - val_loss: 0.1271 - val_accuracy: 0.9622 - lr: 6.2500e-05\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1799 - accuracy: 0.9392 - val_loss: 0.1263 - val_accuracy: 0.9628 - lr: 6.2500e-05\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1746 - accuracy: 0.9445 - val_loss: 0.1243 - val_accuracy: 0.9647 - lr: 3.1250e-05\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1735 - accuracy: 0.9433 - val_loss: 0.1257 - val_accuracy: 0.9632 - lr: 3.1250e-05\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1796 - accuracy: 0.9426 - val_loss: 0.1249 - val_accuracy: 0.9645 - lr: 3.1250e-05\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1704 - accuracy: 0.9434 - val_loss: 0.1248 - val_accuracy: 0.9643 - lr: 3.1250e-05\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1761 - accuracy: 0.9433 - val_loss: 0.1246 - val_accuracy: 0.9647 - lr: 1.5625e-05\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1703 - accuracy: 0.9461 - val_loss: 0.1245 - val_accuracy: 0.9645 - lr: 1.5625e-05\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.1715 - accuracy: 0.9451 - val_loss: 0.1237 - val_accuracy: 0.9650 - lr: 1.5625e-05\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1653 - accuracy: 0.9461 - val_loss: 0.1242 - val_accuracy: 0.9645 - lr: 1.5625e-05\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1695 - accuracy: 0.9439 - val_loss: 0.1238 - val_accuracy: 0.9647 - lr: 1.5625e-05\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1725 - accuracy: 0.9426 - val_loss: 0.1237 - val_accuracy: 0.9645 - lr: 1.5625e-05\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.1703 - accuracy: 0.9442 - val_loss: 0.1238 - val_accuracy: 0.9650 - lr: 7.8125e-06\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1773 - accuracy: 0.9424 - val_loss: 0.1243 - val_accuracy: 0.9647 - lr: 7.8125e-06\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1666 - accuracy: 0.9451 - val_loss: 0.1235 - val_accuracy: 0.9653 - lr: 7.8125e-06\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1630 - accuracy: 0.9461 - val_loss: 0.1236 - val_accuracy: 0.9653 - lr: 7.8125e-06\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1669 - accuracy: 0.9431 - val_loss: 0.1233 - val_accuracy: 0.9653 - lr: 7.8125e-06\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1632 - accuracy: 0.9464 - val_loss: 0.1231 - val_accuracy: 0.9655 - lr: 7.8125e-06\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1640 - accuracy: 0.9463 - val_loss: 0.1235 - val_accuracy: 0.9650 - lr: 7.8125e-06\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1683 - accuracy: 0.9458 - val_loss: 0.1235 - val_accuracy: 0.9657 - lr: 7.8125e-06\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.1639 - accuracy: 0.9469 - val_loss: 0.1232 - val_accuracy: 0.9655 - lr: 7.8125e-06\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.1661 - accuracy: 0.9458 - val_loss: 0.1234 - val_accuracy: 0.9645 - lr: 3.9063e-06\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.1664 - accuracy: 0.9452 - val_loss: 0.1231 - val_accuracy: 0.9655 - lr: 3.9063e-06\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.1679 - accuracy: 0.9465 - val_loss: 0.1234 - val_accuracy: 0.9653 - lr: 3.9063e-06\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.1668 - accuracy: 0.9460 - val_loss: 0.1232 - val_accuracy: 0.9647 - lr: 1.9531e-06\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1613 - accuracy: 0.9459 - val_loss: 0.1231 - val_accuracy: 0.9655 - lr: 1.9531e-06\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1653 - accuracy: 0.9447 - val_loss: 0.1233 - val_accuracy: 0.9645 - lr: 1.9531e-06\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1697 - accuracy: 0.9471 - val_loss: 0.1229 - val_accuracy: 0.9647 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1670 - accuracy: 0.9466 - val_loss: 0.1230 - val_accuracy: 0.9655 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.1707 - accuracy: 0.9440 - val_loss: 0.1231 - val_accuracy: 0.9653 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1708 - accuracy: 0.9452 - val_loss: 0.1231 - val_accuracy: 0.9653 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1655 - accuracy: 0.9476 - val_loss: 0.1231 - val_accuracy: 0.9647 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.1660 - accuracy: 0.9474 - val_loss: 0.1230 - val_accuracy: 0.9653 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.1688 - accuracy: 0.9459 - val_loss: 0.1232 - val_accuracy: 0.9647 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.1713 - accuracy: 0.9451 - val_loss: 0.1232 - val_accuracy: 0.9650 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1703 - accuracy: 0.9451 - val_loss: 0.1231 - val_accuracy: 0.9655 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1618 - accuracy: 0.9489 - val_loss: 0.1231 - val_accuracy: 0.9653 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.1725 - accuracy: 0.9442 - val_loss: 0.1232 - val_accuracy: 0.9650 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "history = model.fit(\n",
    "    ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=False).flow(X_train, y_train, batch_size=64),\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': range(len(predicted_classes)), 'Category': predicted_classes}).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "57e612bb",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
