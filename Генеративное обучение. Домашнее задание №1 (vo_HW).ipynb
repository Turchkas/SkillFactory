{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-KeGw-GCZXk"
      },
      "source": [
        "# Домашнее задание \"Варианционные автоэнкодеры\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPQ-a1t0gOO_"
      },
      "source": [
        "**Автор**: Ермекова Асель\n",
        "\n",
        "В этом домашнем задании вам предстоит реализовать VAE для датасета картинок MNIST.\n",
        "\n",
        "Вы научитесь обучать вариационный автоэнкодер (VAE) генерировать новые изображения с нуля. А также сможете управлять генерацией, указывая желаемый класс объекта, и оценивать качество результата с помощью метрики FID.\n",
        "\n",
        "Это домашнее задание состоит из двух частей:\n",
        "\n",
        "* **I часть.** Реализовать безусловную генерацию картинок при помощи VAE тренированную на датасете MNIST и оценить качество по метрике FID.\n",
        "* **II часть.** Реализовать условную генерацию по классу и оценить качество по метрике FID.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2D3ZgfKISwd"
      },
      "source": [
        "Установите библиотеку для подсчета FID:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhYp4gS8ox32",
        "outputId": "497d1893-e552-4c00-be7b-4994b2d8ed70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-fid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc-Nwikdf1EY"
      },
      "source": [
        "## **I часть. Unconditional VAE (6 баллов)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG1utf_ZoFXj"
      },
      "source": [
        "### Библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CCEPzS2qoHhG"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# Импортните любые необходимые вам библиотеки\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFU4Gu4vkpf5"
      },
      "source": [
        "### Датасет."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3JalSoZqutl"
      },
      "source": [
        "**Задание**: Скачайте датасет MNIST и подготовьте train dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A05qEeP6dll1"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([\n",
        "        transforms.ToTensor(), # [0.0, 1.0] float\n",
        "        transforms.Lambda(lambda x: (x > 0.5).float()) # Binarize\n",
        "        ])\n",
        "    )\n",
        "\n",
        "train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=512,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(), # [0.0, 1.0] float\n",
        "        transforms.Lambda(lambda x: (x > 0.5).float()) # Binarize\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3uNroE4L5Y_"
      },
      "source": [
        "**Задание**: Для FID сохраните 10k реальных изображений из MNIST test части в папку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "urDPJe8DGqGJ"
      },
      "outputs": [],
      "source": [
        "# TODO: Для FID сохраните 10k реальных изображений из MNIST test части в папку\n",
        "\n",
        "os.makedirs('mnist_vae_real', exist_ok=True)\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "    img, _ = test_dataset[i]\n",
        "    save_image(img, f'mnist_vae_real/real_{i:05d}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7HWBHlkq4Du"
      },
      "source": [
        "**Задание**: Визуализируйте 5 рандомных сэмплов из тренировочных данных и 5 сэмплов из тестовых данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "V_ug8vGxCjET",
        "outputId": "830bd59e-6124-4d2d-a61e-ac8e2039f2be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "\n",
        "for i in range(5):\n",
        "    id = random.randint(0, len(train_dataset) - 1)\n",
        "    img, label = train_dataset[id]\n",
        "    axes[0, i].imshow(img[0], cmap='gray')\n",
        "    axes[0, i].set_title(f'Train Sample {i+1}\\nLabel: {label}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "for i in range(5):\n",
        "    id = random.randint(0, len(test_dataset) - 1)\n",
        "    img, label = test_dataset[id]\n",
        "    axes[1, i].imshow(img[0], cmap='gray')\n",
        "    axes[1, i].set_title(f'Test Sample {i+1}\\nLabel: {label}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvsYC-qEkrfd"
      },
      "source": [
        "### Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOE45TA1MHl_"
      },
      "source": [
        "**Задание**: Реализуйте VAE архитектуру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UOTAmalSGlHY"
      },
      "outputs": [],
      "source": [
        "# TODO: Реализуйте VAE (безусловный)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=32, hidden_dim=128):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Encoder: изображение -> mu, logvar\n",
        "        # Decoder: z -> изображение\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim, 32, 4, 2, 1),  # понизим размерность изображения до 14 на 14\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Conv2d(32, 64, 4, 2, 1), # понизим размерность изображения до 7 на 7\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Flatten(), # вытягиваем в одномерный вектор\n",
        "            nn.Linear(3136, hidden_dim), # делаем вектор с 128 координатами из вектора с 3136 координатами\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Linear(hidden_dim, 2 * latent_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim), # делаем вектор с 128 координатами из вектора с 32 координатами\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Linear(hidden_dim, 3136), # делаем вектор с 3136 координатами из вектора с 128 координатами\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Unflatten(1, (64, 7, 7)), # делаем 4D-тензор\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1), # повышаем размерность изображения до 14 на 14\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.ConvTranspose2d(32, input_dim, 4, 2, 1), # повышаем размерность изображения до 28 на 28\n",
        "            nn.Sigmoid() # ф-я активации, которая предсказывает класс пикселя\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        p_recon = self.decode(z)\n",
        "        return p_recon, mu, logvar, z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P4f4GzioPUz"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5Fg_VXFKa0"
      },
      "source": [
        "**Задание**: Напишите VAE Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HP82mY2Pp7iA"
      },
      "outputs": [],
      "source": [
        "# TODO: Реализуйте функцию потерь VAE (подходит и для CVE)\n",
        "\n",
        "def vae_loss(p_recon, x, mu, logvar):\n",
        "    # Reconstruction loss: BCE (since output is sigmoid)\n",
        "    recon_loss = F.binary_cross_entropy(p_recon, x, reduction='sum')\n",
        "    # KL divergence: D_KL(q(z|x) || p(z))\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl_loss, recon_loss, kl_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euSht88Hkt4G"
      },
      "source": [
        "### Тренировка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWA7MSUoo4Fv"
      },
      "source": [
        "**Задание**: Обучите модель на датасете MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zaw-ZH4qo5x3"
      },
      "outputs": [],
      "source": [
        "latent_dim = 32 # MNIST VAEs often use 20–64\n",
        "hidden_dim = 128\n",
        "epochs = 25\n",
        "lr = 1e-3\n",
        "img_size = 28\n",
        "channels = 1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lDJp84sMp_fe"
      },
      "outputs": [],
      "source": [
        "# TODO: Обучите модель\n",
        "\n",
        "def train_vae(model, train_loader, epochs=1000):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  train_losses = []\n",
        "  recon_losses = []\n",
        "  kl_losses = []\n",
        "  best_loss = 1e38\n",
        "  best_model_state = None\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "      total_loss = 0\n",
        "      total_recon = 0\n",
        "      total_kl = 0\n",
        "      num_batches = 0\n",
        "\n",
        "      for i, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')):\n",
        "          x = batch[0].to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          p_recon, mu, logvar, z = model(x)\n",
        "          loss, recon_loss, kl_loss = vae_loss(p_recon, x, mu, logvar)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          total_loss += loss.item()\n",
        "          total_recon += recon_loss.item()\n",
        "          total_kl += kl_loss.item()\n",
        "          num_batches += 1\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader.dataset)\n",
        "      avg_recon = total_recon / len(train_loader.dataset)\n",
        "      avg_kl = total_kl / len(train_loader.dataset)\n",
        "\n",
        "      train_losses.append(avg_loss)\n",
        "      recon_losses.append(avg_recon)\n",
        "      kl_losses.append(avg_kl)\n",
        "\n",
        "      print(f'На эпохе {epoch+1} Loss : {round(avg_loss, 4)}, Recon : {round(avg_recon, 4)}, KL : {round(avg_kl, 4)}')\n",
        "\n",
        "      if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "  print(f'\\nЛучший Loss: {round(best_loss, 4)}')\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  return train_losses, recon_losses, kl_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08S2QyZbNkFp",
        "outputId": "ea2d6089-ac5e-4ab1-a6a9-3330dce9e30b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/25: 100%|██████████| 118/118 [00:09<00:00, 11.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 1 Loss : 238.5951, Recon : 237.2235, KL : 1.3716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/25: 100%|██████████| 118/118 [00:09<00:00, 12.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 2 Loss : 191.8604, Recon : 188.2859, KL : 3.5745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/25: 100%|██████████| 118/118 [00:09<00:00, 12.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 3 Loss : 161.2207, Recon : 150.4278, KL : 10.7929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/25: 100%|██████████| 118/118 [00:11<00:00, 10.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 4 Loss : 137.7216, Recon : 122.2255, KL : 15.496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/25: 100%|██████████| 118/118 [00:10<00:00, 10.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 5 Loss : 123.5395, Recon : 105.5416, KL : 17.9979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/25: 100%|██████████| 118/118 [00:09<00:00, 12.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 6 Loss : 114.9027, Recon : 95.9788, KL : 18.9239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/25: 100%|██████████| 118/118 [00:09<00:00, 12.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 7 Loss : 107.9592, Recon : 88.1451, KL : 19.8141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/25: 100%|██████████| 118/118 [00:09<00:00, 12.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 8 Loss : 103.1629, Recon : 83.0329, KL : 20.13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/25: 100%|██████████| 118/118 [00:09<00:00, 12.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 9 Loss : 99.7749, Recon : 79.4246, KL : 20.3503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/25: 100%|██████████| 118/118 [00:08<00:00, 13.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 10 Loss : 96.6915, Recon : 75.8154, KL : 20.8761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/25: 100%|██████████| 118/118 [00:09<00:00, 12.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 11 Loss : 93.9423, Recon : 72.4132, KL : 21.5291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/25: 100%|██████████| 118/118 [00:09<00:00, 12.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 12 Loss : 91.7479, Recon : 69.6803, KL : 22.0676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/25: 100%|██████████| 118/118 [00:09<00:00, 12.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 13 Loss : 89.9315, Recon : 67.452, KL : 22.4795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/25: 100%|██████████| 118/118 [00:08<00:00, 13.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 14 Loss : 88.4846, Recon : 65.6337, KL : 22.851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/25: 100%|██████████| 118/118 [00:10<00:00, 11.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 15 Loss : 87.2579, Recon : 64.1299, KL : 23.128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/25: 100%|██████████| 118/118 [00:09<00:00, 12.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 16 Loss : 86.1091, Recon : 62.7228, KL : 23.3862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/25: 100%|██████████| 118/118 [00:09<00:00, 12.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 17 Loss : 85.3192, Recon : 61.7325, KL : 23.5868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/25: 100%|██████████| 118/118 [00:08<00:00, 13.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 18 Loss : 84.5262, Recon : 60.7613, KL : 23.7649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/25: 100%|██████████| 118/118 [00:09<00:00, 12.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 19 Loss : 83.9453, Recon : 60.0324, KL : 23.9129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/25: 100%|██████████| 118/118 [00:09<00:00, 12.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 20 Loss : 83.3322, Recon : 59.274, KL : 24.0581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/25: 100%|██████████| 118/118 [00:09<00:00, 12.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 21 Loss : 82.8806, Recon : 58.7471, KL : 24.1335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/25: 100%|██████████| 118/118 [00:09<00:00, 12.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 22 Loss : 82.4048, Recon : 58.1625, KL : 24.2423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/25: 100%|██████████| 118/118 [00:09<00:00, 12.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 23 Loss : 81.9246, Recon : 57.5794, KL : 24.3452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/25: 100%|██████████| 118/118 [00:09<00:00, 12.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 24 Loss : 81.7476, Recon : 57.3382, KL : 24.4094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/25: 100%|██████████| 118/118 [00:09<00:00, 12.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 25 Loss : 81.2453, Recon : 56.7711, KL : 24.4742\n",
            "\n",
            "Лучший Loss: 81.2453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "vae_model = VAE(input_dim=channels, latent_dim=latent_dim, hidden_dim=hidden_dim).to(device)\n",
        "vae_train_losses, vae_recon_losses, vae_kl_losses = train_vae(vae_model, train_loader, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqKZRnxnk2ON"
      },
      "source": [
        "### Метрика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1SCUUjk42O"
      },
      "source": [
        "В этом разделе вам необходимо посчитать метрику FID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Weiu7gOmk_TW"
      },
      "source": [
        "**Что такое FID?**\n",
        "\n",
        "**FID (Fréchet Inception Distance)** — это метрика качества генеративных моделей для изображений, которая измеряет **расстояние между распределениями признаков реальных и сгенерированных изображений** в пространстве предобученной нейросети (обычно Inception-v3).\n",
        "\n",
        "Чем **ниже FID**, тем **ближе** сгенерированные изображения к реальным — как по **качеству**, так и по **разнообразию**.\n",
        "\n",
        "Формула FID основана на предположении, что признаки в этом пространстве приблизительно распределены как **многомерное нормальное распределение**:\n",
        "\n",
        "$$\n",
        "\\text{FID} = \\|\\mu_r - \\mu_g\\|^2 + \\mathrm{Tr}\\left( \\Sigma_r + \\Sigma_g - 2\\sqrt{\\Sigma_r \\Sigma_g} \\right)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $(\\mu_r, \\Sigma_r)$ — среднее и ковариационная матрица признаков **реальных** изображений,\n",
        "- $(\\mu_g, \\Sigma_g)$ — то же для **сгенерированных** изображений,\n",
        "- $\\mathrm{Tr}(\\cdot)$ — след матрицы.\n",
        "\n",
        "> 🔹 FID = 0 означает полное совпадение распределений.  \n",
        "> 🔹 Чем выше FID ↑ , тем качество или разнообразие генерации ниже ↓."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKKlXLdNlCGZ"
      },
      "source": [
        "**Как считать FID на MNIST?**\n",
        "\n",
        "Вычислите FID с помощью библиотеки [`pytorch-fid`](https://github.com/mseitzer/pytorch-fid):\n",
        "\n",
        "```bash\n",
        "python -m pytorch_fid real_mnist/ fake_mnist/ --device cuda\n",
        "```\n",
        "\n",
        "> **Важно**: несмотря на то, что признаки Inception-v3 не оптимальны для рукописных цифр, FID остаётся полезной **относительной метрикой** — она позволяет сравнивать разные модели между собой при одинаковых условиях предобработки.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI93gAkQEg7O"
      },
      "source": [
        "**Задание:** Сгенерируйте и сохраните 10 тыс. изображений, выберите 10 тыс. реальных изображений из MNIST тестовой выборки и посчитайте FID между реальными и сгенерированными изображениями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxAwIJq4zb7A",
        "outputId": "f0108632-5c6d-472f-a949-5a2537645a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Закончил\n"
          ]
        }
      ],
      "source": [
        "# TODO: Сгенерируйте и сохраните 10 тыс. изображений для FID в папке mnist_vae_fake\n",
        "\n",
        "vae_samles = 10000\n",
        "os.makedirs('mnist_vae_fake', exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(vae_samles, vae_model.latent_dim).to(device)\n",
        "    vae_fake_images = vae_model.decode(z)\n",
        "    vae_fake_binary = (vae_fake_images > 0.5).float()\n",
        "    for i in range(vae_samles):\n",
        "        save_image(vae_fake_binary[i], f'mnist_vae_fake/mnist_vae_fake_{i:05d}.png')\n",
        "\n",
        "    print('Закончил')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzL3USg_riUK",
        "outputId": "c56b0a81-192b-406e-af6c-43a25145fbd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-fid in /usr/local/lib/python3.12/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-fid) (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.3)\n",
            "100% 200/200 [00:37<00:00,  5.35it/s]\n",
            "100% 200/200 [00:38<00:00,  5.21it/s]\n",
            "FID:  7.260305620650172\n"
          ]
        }
      ],
      "source": [
        "# Чтобы вычислить FID, запустите в терминале:\n",
        "!pip install pytorch-fid\n",
        "!python -m pytorch_fid mnist_vae_real mnist_vae_fake --device cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw-YrISFHgnu"
      },
      "source": [
        "## **II Часть. Conditional VAE (6 баллов)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVMf6pBnHd8b"
      },
      "source": [
        "Мы уже научились обучать обычный VAE на датасете картинок и получать новые картинки. Давайте теперь научимся обучать модель, которая сможет генерировать не просто рандомную картинку, которая похожа на картинки из датасета, а картинку из конкретного класса. Например, в MNIST датасете 10 классов (от 1 до 10) и мы хотим говорить модели \"Сгенерируй мне только конкретно картинку с числом 3.\" и она должна теперь уже сгенерировать только картинку с числом 3. Как раз Conditional VAE это должен уметь делать и генерировать картинку, обуславливаясь на конкретный класс.\n",
        "\n",
        "\n",
        "**Задание**. В этой части домашнего задания вам предстоит обучить Conditional VAE на MNIST. Это значит, что модель на вход должна принимать картинку и класс картинки.\n",
        "\n",
        "**Метрика**. Вам нужно сгенерировать 1000 сэмплов на каждый класс и посчитать FID для каждого класса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YWFKXSxOJtwS"
      },
      "outputs": [],
      "source": [
        "# TODO: Реализуйте Condiional VAE — добавьте one-hot класс как вход в encoder и decoder\n",
        "\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=32, hidden_dim=128, num_classes=10):\n",
        "        super(CVAE, self).__init__()\n",
        "        # TODO\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        # Архитектура как в VAE\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim + num_classes, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2 * latent_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 3136),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 7, 7)),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, input_dim, 4, 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x, c):\n",
        "        # TODO: конкатенируйте x и c по каналам\n",
        "        c = c.view(c.size(0), c.size(1), 1, 1).expand(-1, -1, x.size(2), x.size(3))\n",
        "        x = torch.cat([x, c], dim=1)\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, c):\n",
        "        # TODO: конкатенируйте z и c\n",
        "        z = torch.cat([z, c], dim=1)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        # TODO\n",
        "        mu, logvar = self.encode(x, c)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        p_recon = self.decode(z, c)\n",
        "        return p_recon, mu, logvar, z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x5KuxfgDtPCi"
      },
      "outputs": [],
      "source": [
        "# TODO: Обучите CVAE\n",
        "\n",
        "def train_cvae(model, train_loader, epochs=1000):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    recon_losses = []\n",
        "    kl_losses = []\n",
        "    best_loss = 1e38\n",
        "    best_model_state = None\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        total_recon = 0\n",
        "        total_kl = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for i, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')):\n",
        "            x = batch[0].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            p_recon, mu, logvar, z = model(x, F.one_hot(batch[1], model.num_classes).float().to(device))\n",
        "            loss, recon_loss, kl_loss = vae_loss(p_recon, x, mu, logvar) # для CVAE ф-я потерь точно такая же, как и для VAE\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_recon += recon_loss.item()\n",
        "            total_kl += kl_loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        avg_recon = total_recon / len(train_loader.dataset)\n",
        "        avg_kl = total_kl / len(train_loader.dataset)\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        recon_losses.append(avg_recon)\n",
        "        kl_losses.append(avg_kl)\n",
        "\n",
        "        print(f'На эпохе {epoch+1} Loss : {round(avg_loss, 4)}, Recon : {round(avg_recon, 4)}, KL : {round(avg_kl, 4)}')\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "              best_loss = avg_loss\n",
        "              best_model_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f'\\nЛучший Loss: {round(best_loss, 4)}')\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return train_losses, recon_losses, kl_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njiup5m3bvIk",
        "outputId": "fc4fb52e-b21e-4ae3-c3cc-02cdb001df95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/25: 100%|██████████| 118/118 [00:14<00:00,  8.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 1 Loss : 226.2578, Recon : 224.1962, KL : 2.0616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/25: 100%|██████████| 118/118 [00:08<00:00, 13.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 2 Loss : 168.9502, Recon : 161.8469, KL : 7.1033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/25: 100%|██████████| 118/118 [00:09<00:00, 12.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 3 Loss : 128.6188, Recon : 114.1587, KL : 14.46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/25: 100%|██████████| 118/118 [00:09<00:00, 12.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 4 Loss : 110.1229, Recon : 92.8585, KL : 17.2644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/25: 100%|██████████| 118/118 [00:09<00:00, 12.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 5 Loss : 100.186, Recon : 81.5671, KL : 18.6189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/25: 100%|██████████| 118/118 [00:09<00:00, 12.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 6 Loss : 93.9578, Recon : 74.6819, KL : 19.276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/25: 100%|██████████| 118/118 [00:09<00:00, 12.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 7 Loss : 89.8649, Recon : 70.0871, KL : 19.7778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/25: 100%|██████████| 118/118 [00:10<00:00, 11.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 8 Loss : 86.8698, Recon : 66.745, KL : 20.1248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/25: 100%|██████████| 118/118 [00:09<00:00, 12.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 9 Loss : 84.8843, Recon : 64.4461, KL : 20.4382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/25: 100%|██████████| 118/118 [00:09<00:00, 12.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 10 Loss : 83.0606, Recon : 62.3105, KL : 20.7501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/25: 100%|██████████| 118/118 [00:09<00:00, 12.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 11 Loss : 81.7496, Recon : 60.8015, KL : 20.9481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/25: 100%|██████████| 118/118 [00:09<00:00, 12.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 12 Loss : 80.6165, Recon : 59.4471, KL : 21.1694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/25: 100%|██████████| 118/118 [00:09<00:00, 12.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 13 Loss : 79.6981, Recon : 58.3761, KL : 21.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/25: 100%|██████████| 118/118 [00:09<00:00, 12.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 14 Loss : 78.9108, Recon : 57.4596, KL : 21.4513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/25: 100%|██████████| 118/118 [00:09<00:00, 12.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 15 Loss : 78.2393, Recon : 56.6555, KL : 21.5839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/25: 100%|██████████| 118/118 [00:09<00:00, 13.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 16 Loss : 77.5725, Recon : 55.8859, KL : 21.6866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/25: 100%|██████████| 118/118 [00:09<00:00, 12.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 17 Loss : 76.9405, Recon : 55.1596, KL : 21.7809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/25: 100%|██████████| 118/118 [00:09<00:00, 12.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 18 Loss : 76.4016, Recon : 54.4744, KL : 21.9272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/25: 100%|██████████| 118/118 [00:09<00:00, 12.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 19 Loss : 75.9534, Recon : 53.9477, KL : 22.0057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/25: 100%|██████████| 118/118 [00:09<00:00, 13.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 20 Loss : 75.5222, Recon : 53.437, KL : 22.0851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/25: 100%|██████████| 118/118 [00:09<00:00, 12.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 21 Loss : 75.1616, Recon : 52.9812, KL : 22.1804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/25: 100%|██████████| 118/118 [00:09<00:00, 12.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 22 Loss : 74.7717, Recon : 52.5232, KL : 22.2485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/25: 100%|██████████| 118/118 [00:09<00:00, 12.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 23 Loss : 74.3923, Recon : 52.0691, KL : 22.3232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/25: 100%|██████████| 118/118 [00:09<00:00, 11.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 24 Loss : 74.0179, Recon : 51.6708, KL : 22.3471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/25: 100%|██████████| 118/118 [00:09<00:00, 13.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 25 Loss : 73.8167, Recon : 51.4182, KL : 22.3985\n",
            "\n",
            "Лучший Loss: 73.8167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "cvae_model = CVAE(input_dim=channels, latent_dim=latent_dim, hidden_dim=hidden_dim, num_classes=num_classes).to(device)\n",
        "cvae_train_losses, cvae_recon_losses, cvae_kl_losses = train_cvae(cvae_model, train_loader, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STtYG45mYOw8",
        "outputId": "59a8a5ff-cc2e-4490-88c6-1d393488333b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Закончил\n"
          ]
        }
      ],
      "source": [
        "# TODO: Сгенерируйте 1000 сэмплов для каждого класса при помощи CVAE модели\n",
        "\n",
        "cvae_samles = 1000\n",
        "cvae_model.eval()\n",
        "\n",
        "os.makedirs('fake_per_class', exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(num_classes):\n",
        "        class_dir = f'fake_per_class/class_{i}'\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        cvae_fake_images = cvae_model.decode(torch.randn(cvae_samles, cvae_model.latent_dim).to(device), torch.eye(num_classes).to(device)[[i]*cvae_samles])\n",
        "        cvae_fake_binary = (cvae_fake_images > 0.5).float()\n",
        "\n",
        "        for j in range(cvae_fake_binary.shape[0]):\n",
        "            save_image(cvae_fake_binary[j], f'{class_dir}/fake_{j:05d}.png')\n",
        "\n",
        "    print('Закончил')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS0dfUCsJ4o_",
        "outputId": "65fe39e7-0b65-426e-9470-75f524bb3059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Закончил\n"
          ]
        }
      ],
      "source": [
        "# TODO: Сохраните 1000 сэмплов для каждого класса из реального датасета MNIST тестовой части\n",
        "\n",
        "real_mnist_samples = 1000\n",
        "os.makedirs('real_per_class', exist_ok=True)\n",
        "\n",
        "class_dict = {i: [] for i in range(10)}\n",
        "for i, (_, label) in enumerate(test_dataset):\n",
        "    if len(class_dict[label]) < real_mnist_samples:\n",
        "        class_dict[label].append(i)\n",
        "\n",
        "for i, id in class_dict.items():\n",
        "    class_dir = f'real_per_class/class_{i}'\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "    for i, j in enumerate(id):\n",
        "        img, _ = test_dataset[j]\n",
        "        save_image(img, f'{class_dir}/real_{i:05d}.png')\n",
        "\n",
        "print('Закончил')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Voii0NlN7i8t",
        "outputId": "ef5cef8e-04da-4f4e-c8aa-c666fb9ff24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class 0\n",
            "100% 20/20 [00:04<00:00,  4.89it/s]\n",
            "100% 20/20 [00:03<00:00,  5.10it/s]\n",
            "FID:  7.81936842439103\n",
            "\n",
            "Class 1\n",
            "100% 20/20 [00:04<00:00,  4.75it/s]\n",
            "100% 20/20 [00:03<00:00,  5.04it/s]\n",
            "FID:  14.973688835742252\n",
            "\n",
            "Class 2\n",
            "100% 20/20 [00:04<00:00,  4.58it/s]\n",
            "100% 20/20 [00:03<00:00,  5.09it/s]\n",
            "FID:  11.772271477459498\n",
            "\n",
            "Class 3\n",
            "100% 20/20 [00:04<00:00,  4.76it/s]\n",
            "100% 20/20 [00:03<00:00,  5.07it/s]\n",
            "FID:  6.077965681633202\n",
            "\n",
            "Class 4\n",
            "100% 20/20 [00:04<00:00,  4.83it/s]\n",
            "100% 20/20 [00:03<00:00,  5.08it/s]\n",
            "FID:  9.097561386226971\n",
            "\n",
            "Class 5\n",
            "100% 18/18 [00:03<00:00,  4.73it/s]\n",
            "100% 20/20 [00:03<00:00,  5.09it/s]\n",
            "FID:  8.482793145766806\n",
            "\n",
            "Class 6\n",
            "100% 20/20 [00:04<00:00,  4.91it/s]\n",
            "100% 20/20 [00:03<00:00,  5.09it/s]\n",
            "FID:  8.915816865426578\n",
            "\n",
            "Class 7\n",
            "100% 20/20 [00:04<00:00,  4.79it/s]\n",
            "100% 20/20 [00:03<00:00,  5.07it/s]\n",
            "FID:  10.815421077622602\n",
            "\n",
            "Class 8\n",
            "100% 20/20 [00:04<00:00,  4.85it/s]\n",
            "100% 20/20 [00:03<00:00,  5.05it/s]\n",
            "FID:  10.37218851342513\n",
            "\n",
            "Class 9\n",
            "100% 20/20 [00:04<00:00,  4.74it/s]\n",
            "100% 20/20 [00:04<00:00,  4.99it/s]\n",
            "FID:  7.493960458235335\n"
          ]
        }
      ],
      "source": [
        "# TODO: Посчитайте FID для каждого класса между сгенерированными и реальными изображениями\n",
        "# Example:\n",
        "#print(\"Class 0\")\n",
        "#!python -m pytorch_fid real_per_class/class_0 fake_per_class/class_0 --device cuda\n",
        "\n",
        "for i in range(num_classes):\n",
        "    print(f\"\\nClass {i}\")\n",
        "    real_dir = f'real_per_class/class_{i}'\n",
        "    fake_dir = f'fake_per_class/class_{i}'\n",
        "    !python -m pytorch_fid {real_dir} {fake_dir} --device cuda"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
